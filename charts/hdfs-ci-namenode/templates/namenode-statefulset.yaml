# A headless service to create DNS records.
apiVersion: v1
kind: Service
metadata:
  name: {{ template "hdfs-ci.namenode.fullname" . }}
  labels:
    app: {{ template "hdfs-ci.namenode.name" . }}
    chart: {{ template "hdfs-ci.subchart" . }}
    release: {{ .Release.Name }}
spec:
  ports:
  - port: 8020
    name: fs
  - port: 50070
    name: webhdfs
  clusterIP: None
  selector:
    app: {{ template "hdfs-ci.namenode.name" . }}
    release: {{ .Release.Name }}
---
# Provides namenode helper scripts. Most of them are start scripts
# that meet different needs.
# TODO: Support upgrade of metadata in case a new Hadoop version requires it.
apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ template "hdfs-ci.namenode.fullname" . }}-scripts
  labels:
    app: {{ template "hdfs-ci.namenode.name" . }}
    chart: {{ template "hdfs-ci.subchart" . }}
    release: {{ .Release.Name }}
data:
  # A bootstrap script which will start namenode daemons after conducting
  # optional metadata initialization steps. The metadata initialization
  # steps will take place in case the metadata dir is empty, which will
  # be the case only for the very first run.
  format-and-run.sh: |
    #!/usr/bin/env bash
    # Exit on error. Append "|| true" if you expect an error.
    set -o errexit
    # Exit on error inside any functions or subshells.
    set -o errtrace
    # Do not allow use of undefined vars. Use ${VAR:-} to use an undefined VAR
    set -o nounset
    # Catch an error in command pipes. e.g. mysqldump fails (but gzip succeeds)
    # in `mysqldump |gzip`
    set -o pipefail
    # Turn on traces, useful while debugging.
    set -o xtrace

    _HDFS_BIN=$HADOOP_PREFIX/bin/hdfs
    _METADATA_DIR=/hadoop/dfs/name/current
    if [[ ! -d $_METADATA_DIR ]]; then
        $_HDFS_BIN --config $HADOOP_CONF_DIR namenode -format  \
            -nonInteractive hdfs-ci ||
            (rm -rf $_METADATA_DIR; exit 1)
    fi
    $_HDFS_BIN --config $HADOOP_CONF_DIR namenode

  # A start script that will just hang indefinitely. A user can then get
  # inside the pod and debug. Or a user can conduct a custom manual operations.
  do-nothing.sh: |
    #!/usr/bin/env bash
    tail -f /var/log/dmesg

  # A start script that has user specified content. Can be used to conduct
  # ad-hoc operation as specified by a user.
  custom-run.sh: {{ .Values.customRunScript | quote }}
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: {{ template "hdfs-ci.namenode.fullname" . }}
  labels:
    app: {{ template "hdfs-ci.namenode.name" . }}
    chart: {{ template "hdfs-ci.subchart" . }}
    release: {{ .Release.Name }}
spec:
  selector:
    matchLabels:
      app: {{ template "hdfs-ci.namenode.name" . }}
      release: {{ .Release.Name }}
  serviceName: {{ template "hdfs-ci.namenode.fullname" . }}
  # Create a size-1 set.
  replicas: 1
  template:
    metadata:
      labels:
        app: {{ template "hdfs-ci.namenode.name" . }}
        release: {{ .Release.Name }}
      {{- if .Values.podAnnotations }}
      annotations:
{{ toYaml .Values.podAnnotations | indent 8 }}
      {{- end }}
    spec:
      {{- if .Values.affinity }}
      affinity:
{{ toYaml .Values.affinity | indent 8 }}
      {{- end }}
      {{- if .Values.nodeSelector }}
      nodeSelector:
{{ toYaml .Values.nodeSelector | indent 8 }}
      {{- end }}
      {{- if .Values.tolerations }}
      tolerations:
{{ toYaml .Values.tolerations | indent 8 }}
      {{- end }}
      # Use hostNetwork so datanodes connect to namenode without going through an overlay network
      # like weave. Otherwise, namenode fails to see physical IP address of datanodes.
      hostNetwork: true
      hostPID: true
      dnsPolicy: ClusterFirstWithHostNet
      containers:
        - name: hdfs-namenode
          image: uhopper/hadoop-namenode:2.8.1
          env:
            - name: HADOOP_CUSTOM_CONF_DIR
              value: /etc/hadoop-custom-conf
            - name: CLUSTER_NAME
              value: hdfs-ci
            # Used by the start script below.
            - name: MY_POD
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
          ports:
          - containerPort: 8020
            name: fs
          - containerPort: 50070
            name: webhdfs
          command: ['/bin/sh', '-c']
          # The start script is provided by a config map.
          args:
            - /entrypoint.sh "/nn-scripts/{{ .Values.namenodeStartScript }}"
          volumeMounts:
            - name: nn-scripts
              mountPath: /nn-scripts
              readOnly: true
            - name: hdfs-name
              mountPath: /hadoop/dfs/name
            - name: hdfs-config
              mountPath: /etc/hadoop-custom-conf
              readOnly: true
            {{- if .Values.global.kerberosEnabled }}
            - name: kerberos-config
              mountPath: /etc/krb5.conf
              subPath: {{ .Values.global.kerberosConfigFileName }}
              readOnly: true
            - name: kerberos-keytab-copy
              mountPath: /etc/security/
              readOnly: true
            {{- end }}
      {{- if .Values.global.kerberosEnabled }}
      initContainers:
        - name: copy-kerberos-keytab
          image: busybox:1.27.1
          command: ['sh', '-c']
          args:
            - cp /kerberos-keytabs/${MY_KERBEROS_NAME}*.keytab /kerberos-keytab-copy/hdfs.keytab
          env:
            - name: MY_KERBEROS_NAME
              valueFrom:
                fieldRef:
                {{- if .Values.hostNetworkEnabled }}
                  fieldPath: spec.nodeName
                {{- else }}
                  fieldPath: metadata.name
                {{- end }}
          volumeMounts:
            - name: kerberos-keytabs
              mountPath: /kerberos-keytabs
            - name: kerberos-keytab-copy
              mountPath: /kerberos-keytab-copy
      {{- end }}
      restartPolicy: Always
      volumes:
        - name: nn-scripts
          configMap:
            name: {{ template "hdfs-ci.namenode.fullname" . }}-scripts
            defaultMode: 0744
        - name: hdfs-config
          configMap:
            name: {{ template "hdfs-ci.config.fullname" . }}
        {{- if .Values.global.kerberosEnabled }}
        - name: kerberos-config
          configMap:
            name: {{ template "krb5-configmap" . }}
        - name: kerberos-keytabs
          secret:
            secretName: {{ template "krb5-keytabs-secret" . }}
        - name: kerberos-keytab-copy
          emptyDir: {}
        {{- end }}
  volumeClaimTemplates:
    - metadata:
        name: hdfs-name
      spec:
        accessModes:
          - {{ .Values.persistence.accessMode }}
        resources:
          requests:
            storage: {{ .Values.persistence.size }}
      {{- if .Values.persistence.storageClass }}
        {{- if (eq "-" .Values.persistence.storageClass) }}
        storageClassName: ""
        {{- else }}
        storageClassName: "{{ .Values.persistence.storageClass }}"
        {{- end }}
      {{- end }}
       {{- if .Values.persistence.selector }}
        selector:
{{ toYaml .Values.persistence.selector | indent 10 }}
       {{- end }}
